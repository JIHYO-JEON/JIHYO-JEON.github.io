---
layout: post
title: "Popular Machine Learning Algorithms"
date: 2020-09-01 20:46:00
tags: [Machine Learning]
---

# Popular Machine Learning Algorithms

## 1. Naive Bayes
Naive Bayes is a simple technique for creating classifiers that are trained using multiple algorithms based on general principles rather than training through a single algorithm. All Nave Bayes classifiers commonly assume that all characteristic values are **independent** of each other. For example, characteristics that enable a particular fruit to be classified as apples (ex. round, red, 10 cm in diameter) assume that there is no possible association between characteristics in the Naive Bayes classifier and each characteristic is considered to contribute independently to the probability that a particular fruit is an apple.

The advantages of Naive Bayes are as follows. **First, in some probability models, the Naive Bayes classification can be trained very efficiently in supervised learning environments.** In many practical applications, the parameter estimation of the Naive Bayes model uses the Maximum Likelihood Estimation (MLE), which can be trained without using Bayes probability theory or Bayesian methods. **Second, the amount of training data for estimating the parameters required for classification is very small.** **Third, despite its simple design and simple assumptions, the Naive Bayes classification works well in many complex real-world situations.**

## 2. Support Vector Machine
Support vector machines (SVM) is a supervised learning model for pattern recognition, data analysis, and mainly for classification and regression. Given a set of data belonging to either category, the SVM algorithm creates an unlikely binary linear classification model that determines which category the new data belongs to based on a given set of data. The classification model created is represented by the boundaries in the space where the data are thought of, and the SVM algorithm is the algorithm for **finding the boundaries with the largest width among them**. 

Typically, support vector machines consist of a set of hyperplanes or hyperplanes available for classification or regression analysis. Intuitively, **good classification requires finding the superplane with the longest distance from the nearest learning data for any classified point**.

## 3. Decision Tree
Decision tree learning is a commonly used methodology in data mining, which aims to generate a model that predicts the value of the target variable based on several input variables.

![enter image description here](https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/CART_tree_titanic_survivors_KOR.png/723px-CART_tree_titanic_survivors_KOR.png)

The learning of a decision tree is the process of dividing the dataset used for learning into subsets according to appropriate **segmentation criteria or segmentation tests**. This process recursively **repeats itself** on each divided subset of data in a way called circular segmentation, and continues until the segmentation no longer adds a new prediction value or until the nodes in the subset have the same value as the target variable. This top-down induction of decision trees is an example of a greedy algorithm and is the most common way to learn a decision tree from data.

## 4. K- Nearest Neighbor (KNN)

K-Nearest Neighbor is a classification algorithm used in machine learning. Data with similar characteristics are used under the assumption that they tend to fall into similar categories.

![Find](https://lh3.googleusercontent.com/proxy/YpJg8__EgkDDfCwlP1hepH2PuuuSIEmX1X1LD6yryf-hOZ8uA174P9sfP50LH5ExaiFapFHqlwe8yVSzuL_JLozVUgyYF_vT2iFATfN16fR2nX85Y5A9sDCljLTiyT6HY_P03a17CtAPfIQCqWmjpB2GKizm-d6jXFhg_lnmcJQvHHhS4KNkO9xCr0BWpelPqZLni42SCEoopvNOb6fW31WkDPNaNloOKA1B5-LaWDGAAFvIwgYhxO8l4UnLTr7S74vJWwjLn1S-xIvDZ2bUqN-jwxv3Dto)

## 5. K- means

The k-means clustering algorithm is an algorithm that groups a given data into k clusters, which works in a way that minimizes the variance of distance differences from each cluster.

![enter image description here](https://blog.kakaocdn.net/dn/bkECov/btqEAMDc6RK/rBSggFFHQkR0GsA0MSGaKK/img.png)

### Further Reading

[KNN vs K-means](https://harshkr21august.medium.com/knn-and-kmeans-b741dfccb69)
**K-nearest neighbors algorithm** is a *supervised* method used for classification and regression problems, widely used in classification problems.
**K-means** is an *unsupervised* learning algorithm used for clustering problem. 
